# model_trainer.py
import os
import joblib
import pandas as pd
import numpy as np
import json
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score, 
                             recall_score, f1_score, confusion_matrix)

class ModelBenchmark:
    """æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°åŸºå‡†æµ‹è¯•ç±»"""
    
    def __init__(self, random_state=42, test_size=0.15, val_size=0.17647):
        """
        åˆå§‹åŒ–åŸºå‡†æµ‹è¯•å™¨
        :param random_state: éšæœºç§å­
        :param test_size: æµ‹è¯•é›†æ¯”ä¾‹
        :param val_size: éªŒè¯é›†æ¯”ä¾‹ï¼ˆç›¸å¯¹äºè®­ç»ƒéªŒè¯é›†ï¼‰
        """
        self.random_state = random_state
        self.test_size = test_size
        self.val_size = val_size
        self.pipelines = {}
        self.results = {}
        self.output_dir = os.path.join(os.getcwd(), "data_outputs")
        os.makedirs(self.output_dir, exist_ok=True)
    
    def run(self, df):
        """æ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹"""
        print("\n" + "="*50)
        print("å¼€å§‹æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°...")
        print("="*50)
        
        # 1. æ•°æ®å‡†å¤‡
        X, y = self._prepare_data(df)
        
        # 2. æ•°æ®åˆ†å‰²
        X_train, X_val, X_test, y_train, y_val, y_test = self._split_data(X, y)
        print(f"\nâœ… æ•°æ®å‡†å¤‡å®Œæˆ:")
        print(f"   - è®­ç»ƒé›†: {len(X_train)} æ¡")
        print(f"   - éªŒè¯é›†: {len(X_val)} æ¡")
        print(f"   - æµ‹è¯•é›†: {len(X_test)} æ¡")
        
        # 3. æ„å»ºé¢„å¤„ç†ç®¡é“
        preprocessor = self._build_preprocessor(X)
        
        # 4. æ„å»ºæ¨¡å‹ç®¡é“
        self._build_pipelines(preprocessor)
        
        # 5. è®­ç»ƒæ‰€æœ‰æ¨¡å‹
        self._train_models(X_train, y_train)
        
        # 6. è¯„ä¼°æ‰€æœ‰æ¨¡å‹
        self._evaluate_models(X_test, y_test)
        
        # 7. ä¿å­˜æ¨¡å‹å’Œç»“æœ
        self._save_models()
        self._save_results()
        
        # 8. ç”ŸæˆæŠ¥å‘Š
        self._generate_feature_importance_report(X_train)
        
        print("\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        
        return self.results
    
    def _prepare_data(self, df):
        """å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡"""
        # å‡è®¾æœ€åä¸€åˆ—æ˜¯ç›®æ ‡
        X = df.iloc[:, :-1]
        y = df.iloc[:, -1]
        
        # æ ‡ç­¾æ˜ å°„ï¼šç¡®ä¿æ˜¯äºŒåˆ†ç±» 0/1
        unique_vals = sorted(y.unique())
        if len(unique_vals) == 2:
            if set(unique_vals) == {1, 2}:
                mapping = {1: 0, 2: 1}
            else:
                mapping = {unique_vals[0]: 0, unique_vals[1]: 1}
            y = y.map(mapping)
            print(f"\nğŸ¯ æ ‡ç­¾æ˜ å°„: {mapping}")
        else:
            print(f"âš ï¸ è­¦å‘Š: ç›®æ ‡å˜é‡ä¸æ˜¯äºŒåˆ†ç±»ï¼å”¯ä¸€å€¼: {unique_vals}")
        
        return X, y
    
    def _split_data(self, X, y):
        """åˆ†å±‚åˆ†å‰²æ•°æ®ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰"""
        # ç¬¬ä¸€æ¬¡åˆ†å‰²ï¼šåˆ†å‡ºæµ‹è¯•é›†
        X_trainval, X_test, y_trainval, y_test = train_test_split(
            X, y, test_size=self.test_size, stratify=y, random_state=self.random_state
        )
        
        # ç¬¬äºŒæ¬¡åˆ†å‰²ï¼šä»è®­ç»ƒéªŒè¯é›†ä¸­åˆ†å‡ºéªŒè¯é›†
        # val_sizeæ˜¯ç›¸å¯¹äºtrainvalçš„æ¯”ä¾‹ï¼Œæœ€ç»ˆæ¯”ä¾‹ä¸º: train(70%) / val(15%) / test(15%)
        X_train, X_val, y_train, y_val = train_test_split(
            X_trainval, y_trainval, test_size=self.val_size, 
            stratify=y_trainval, random_state=self.random_state
        )
        
        return X_train, X_val, X_test, y_train, y_val, y_test
    
    def _build_preprocessor(self, X):
        """æ„å»ºé¢„å¤„ç†ç®¡é“"""
        numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = [c for c in X.columns if c not in numeric_cols]
        
        print(f"\nğŸ”„ æ„å»ºé¢„å¤„ç†ç®¡é“:")
        print(f"   - æ•°å€¼å‹ç‰¹å¾: {len(numeric_cols)}ä¸ª")
        print(f"   - ç±»åˆ«å‹ç‰¹å¾: {len(categorical_cols)}ä¸ª")
        
        # æ•°å€¼å‹ç®¡é“
        numeric_transformer = Pipeline(steps=[
            ('scaler', StandardScaler())
        ])
        
        # ç±»åˆ«å‹ç®¡é“ï¼ˆå…¼å®¹ä¸åŒsklearnç‰ˆæœ¬ï¼‰
        try:
            categorical_transformer = Pipeline(steps=[
                ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))
            ])
        except TypeError:
            categorical_transformer = Pipeline(steps=[
                ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
            ])
        
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_cols),
                ('cat', categorical_transformer, categorical_cols)
            ]
        )
        
        return preprocessor
    
    def _build_pipelines(self, preprocessor):
        """æ„å»ºæ‰€æœ‰æ¨¡å‹ç®¡é“"""
        print("\nğŸ¤– æ„å»ºæ¨¡å‹ç®¡é“:")
        
        # é€»è¾‘å›å½’
        self.pipelines['logistic_regression'] = Pipeline(steps=[
            ('pre', preprocessor),
            ('clf', LogisticRegression(
                max_iter=2000, class_weight='balanced', random_state=self.random_state
            ))
        ])
        print("   - âœ… é€»è¾‘å›å½’")
        
        # éšæœºæ£®æ—
        self.pipelines['random_forest'] = Pipeline(steps=[
            ('pre', preprocessor),
            ('clf', RandomForestClassifier(
                n_estimators=200, random_state=self.random_state, 
                class_weight='balanced', n_jobs=-1
            ))
        ])
        print("   - âœ… éšæœºæ£®æ—")
        
        # XGBoostï¼ˆå¯é€‰ï¼‰
        try:
            from xgboost import XGBClassifier
            self.pipelines['xgboost'] = Pipeline(steps=[
                ('pre', preprocessor),
                ('clf', XGBClassifier(
                    use_label_encoder=False, eval_metric='logloss',
                    random_state=self.random_state, n_jobs=-1
                ))
            ])
            print("   - âœ… XGBoost")
        except ImportError:
            print("   - âš ï¸ XGBoostä¸å¯ç”¨ï¼Œå·²è·³è¿‡")
        
        # TabNetï¼ˆå¯é€‰ï¼Œç”¨äºæå‡ç®—æ³•å¤æ‚åº¦ï¼‰
        try:
            from pytorch_tabnet import TabNetClassifier
            self.pipelines['tabnet'] = Pipeline(steps=[
                ('pre', preprocessor),
                ('clf', TabNetClassifier(
                    seed=self.random_state, verbose=0
                ))
            ])
            print("   - âœ… TabNet")
        except ImportError:
            print("   - â„¹ï¸ TabNetæœªå®‰è£…ï¼Œä¸å½±å“æ ¸å¿ƒåŠŸèƒ½")
    
    def _train_models(self, X_train, y_train):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        print("\nğŸ“ å¼€å§‹è®­ç»ƒæ¨¡å‹:")
        
        for name, pipeline in self.pipelines.items():
            print(f"\n   â†’ è®­ç»ƒ {name}...")
            pipeline.fit(X_train, y_train)
            print(f"      âœ… è®­ç»ƒå®Œæˆ")
    
    def _evaluate_models(self, X_test, y_test):
        """è¯„ä¼°æ‰€æœ‰æ¨¡å‹"""
        print("\nğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ:")
        
        for name, pipeline in self.pipelines.items():
            print(f"\n   â†’ è¯„ä¼° {name}:")
            
            # é¢„æµ‹
            y_pred = pipeline.predict(X_test)
            y_proba = None
            
            # é¢„æµ‹æ¦‚ç‡æˆ–å†³ç­–å‡½æ•°
            if hasattr(pipeline.named_steps['clf'], 'predict_proba'):
                y_proba = pipeline.predict_proba(X_test)[:, 1]
            elif hasattr(pipeline.named_steps['clf'], 'decision_function'):
                y_proba = pipeline.decision_function(X_test)
            
            # è®¡ç®—æŒ‡æ ‡
            metrics = {
                'accuracy': float(accuracy_score(y_test, y_pred)),
                'precision': float(precision_score(y_test, y_pred, zero_division=0)),
                'recall': float(recall_score(y_test, y_pred, zero_division=0)),
                'f1': float(f1_score(y_test, y_pred, zero_division=0)),
                'confusion_matrix': confusion_matrix(y_test, y_pred).tolist()
            }
            
            # è®¡ç®—AUCï¼ˆå¦‚æœæœ‰æ¦‚ç‡ï¼‰
            if y_proba is not None:
                try:
                    metrics['roc_auc'] = float(roc_auc_score(y_test, y_proba))
                except Exception as e:
                    metrics['roc_auc'] = None
                    print(f"      âš ï¸ AUCè®¡ç®—å¤±è´¥: {e}")
            else:
                metrics['roc_auc'] = None
            
            self.results[name] = metrics
            
            # æ‰“å°ç»“æœ
            print(f"      - Accuracy: {metrics['accuracy']:.4f}")
            print(f"      - Precision: {metrics['precision']:.4f}")
            print(f"      - Recall: {metrics['recall']:.4f}")
            print(f"      - F1: {metrics['f1']:.4f}")
            print(f"      - ROC AUC: {metrics['roc_auc']:.4f}")
    
    def _save_models(self):
        """ä¿å­˜æ‰€æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹"""
        models_dir = os.path.join(self.output_dir, "models")
        os.makedirs(models_dir, exist_ok=True)
        
        print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹è‡³: {models_dir}")
        
        for name, pipeline in self.pipelines.items():
            model_path = os.path.join(models_dir, f"model_{name}.joblib")
            joblib.dump(pipeline, model_path)
            print(f"   - âœ… {name} å·²ä¿å­˜")
    
    def _save_results(self):
        """ä¿å­˜è¯„ä¼°ç»“æœåˆ°JSON"""
        results_file = os.path.join(self.output_dir, "models", "metrics.json")
        os.makedirs(os.path.dirname(results_file), exist_ok=True)
        
        # æ·»åŠ æœ€ä½³æ¨¡å‹ä¿¡æ¯
        if self.results:
            best_model = max(self.results.items(), key=lambda x: x[1].get('roc_auc', 0))
            self.results['best_model'] = best_model[0]
            self.results['best_auc'] = best_model[1].get('roc_auc')
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ è¯„ä¼°ç»“æœå·²ä¿å­˜: {results_file}")
    
    def _generate_feature_importance_report(self, X_train):
        """ç”Ÿæˆç‰¹å¾é‡è¦æ€§æŠ¥å‘Šï¼ˆä»…éšæœºæ£®æ—ï¼‰"""
        if 'random_forest' not in self.pipelines:
            return
        
        print("\nğŸ“ˆ ç”Ÿæˆç‰¹å¾é‡è¦æ€§æŠ¥å‘Š:")
        
        try:
            # è·å–é¢„å¤„ç†åç‰¹å¾å
            pre = self.pipelines['random_forest'].named_steps['pre']
            
            # æ•°å€¼å‹ç‰¹å¾å
            num_features = X_train.select_dtypes(include=[np.number]).columns.tolist()
            
            # ç±»åˆ«å‹ç‰¹å¾åï¼ˆç‹¬çƒ­ç¼–ç åï¼‰
            cat_features = []
            if 'cat' in pre.named_transformers_:
                ohe = pre.named_transformers_['cat'].named_steps['onehot']
                cat_cols = [c for c in X_train.columns if c not in num_features]
                try:
                    cat_features = list(ohe.get_feature_names_out(cat_cols))
                except:
                    cat_features = []
            
            all_features = num_features + cat_features
            
            # è·å–é‡è¦æ€§
            importances = self.pipelines['random_forest'].named_steps['clf'].feature_importances_
            
            if len(importances) == len(all_features):
                # ä¿å­˜åˆ°CSV
                fi_df = pd.DataFrame({
                    'feature': all_features,
                    'importance': importances
                }).sort_values('importance', ascending=False)
                
                fi_path = os.path.join(self.output_dir, "models", "feature_importance.csv")
                fi_df.to_csv(fi_path, index=False)
                print(f"   - âœ… ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜: {fi_path}")
            else:
                print(f"   - âš ï¸ ç‰¹å¾æ•°é‡ä¸åŒ¹é…ï¼Œè·³è¿‡")
        
        except Exception as e:
            print(f"   - âš ï¸ ç”Ÿæˆå¤±è´¥: {e}")


# ==================== æ¨¡å—è‡ªæµ‹ä»£ç  ====================
if __name__ == '__main__':
    print("="*60)
    print("æ¨¡å‹è®­ç»ƒæ¨¡å—è‡ªæµ‹")
    print("="*60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…ä½¿ç”¨æ—¶è¯·æ›¿æ¢ä¸ºçœŸå®æ•°æ®ï¼‰
    from data_manager import DataManager
    
    # è·å–æ•°æ®
    dm = DataManager()
    df = dm.load_from_local() or dm.fetch_and_save()
    
    # æ‰§è¡Œè®­ç»ƒ
    benchmark = ModelBenchmark()
    results = benchmark.run(df)
    
    print("\nâœ… è‡ªæµ‹å®Œæˆï¼æœ€ä½³æ¨¡å‹:", results.get('best_model'))