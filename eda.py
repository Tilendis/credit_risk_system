# eda.py
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


class EDAAnalyzer:
    """æ¢ç´¢æ€§æ•°æ®åˆ†æç±»ï¼šè‡ªåŠ¨å®Œæˆæ•°æ®è´¨é‡æ£€æµ‹ä¸å¯è§†åŒ–"""
    
    def __init__(self, df, output_dir):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        :param df: å¾…åˆ†æçš„DataFrameï¼ˆåŒ…å«ç‰¹å¾å’Œç›®æ ‡ï¼‰
        :param output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        """
        self.df = df
        self.output_dir = output_dir
        self.plots_dir = os.path.join(output_dir, "eda_plots")
        # è‡ªåŠ¨åˆ›å»ºå›¾è¡¨è¾“å‡ºç›®å½•
        os.makedirs(self.plots_dir, exist_ok=True)
        
        # è‡ªåŠ¨è¯†åˆ«ç›®æ ‡åˆ—ï¼ˆå‡è®¾æœ€åä¸€åˆ—æ˜¯ç›®æ ‡ï¼‰
        self.target_col = df.columns[-1]
        print(f"ğŸ“Š ç›®æ ‡åˆ—è‡ªåŠ¨è¯†åˆ«ä¸º: '{self.target_col}'")
    
    def run_full_analysis(self):
        """æ‰§è¡Œå®Œæ•´EDAæµç¨‹å¹¶ä¿å­˜æ‰€æœ‰ç»“æœ"""
        print("\n" + "="*50)
        print("å¼€å§‹æ‰§è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æ(EDA)...")
        print("="*50)
        
        self._basic_info()
        self._target_analysis()
        self._feature_analysis()
        self._generate_plots()
        
        print("\nâœ… EDAåˆ†æå®Œæˆï¼")
        print(f"   - æ•°æ®æ‘˜è¦: {os.path.join(self.output_dir, 'eda_summary.csv')}")
        print(f"   - å›¾è¡¨æ–‡ä»¶: {self.plots_dir}")
    
    def _basic_info(self):
        """æ‰“å°åŸºç¡€æ•°æ®ä¿¡æ¯"""
        print("\nã€1ã€‘åŸºç¡€ä¿¡æ¯")
        print(f"   - æ•°æ®å½¢çŠ¶: {self.df.shape[0]}è¡Œ Ã— {self.df.shape[1]}åˆ—")
        print(f"   - å†…å­˜å ç”¨: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        # æ•°æ®ç±»å‹ç»Ÿè®¡
        dtype_counts = self.df.dtypes.value_counts()
        print("   - æ•°æ®ç±»å‹ç»Ÿè®¡:")
        for dtype, count in dtype_counts.items():
            print(f"      * {dtype}: {count}åˆ—")
        
        # ç¼ºå¤±å€¼ç»Ÿè®¡
        missings = self.df.isnull().sum()
        if missings.sum() > 0:
            print("   - ç¼ºå¤±å€¼è­¦å‘Š:")
            print(missings[missings > 0])
        else:
            print("   - ç¼ºå¤±å€¼: æ—  (0)")
    
    def _target_analysis(self):
        """åˆ†æç›®æ ‡å˜é‡åˆ†å¸ƒ"""
        print("\nã€2ã€‘ç›®æ ‡å˜é‡åˆ†æ")
        target_series = self.df[self.target_col]
        
        # ç»Ÿè®¡åˆ†å¸ƒ
        counts = target_series.value_counts(dropna=False)
        percents = target_series.value_counts(normalize=True, dropna=False) * 100
        
        print(f"   - ç±»åˆ«åˆ†å¸ƒ:")
        for val in counts.index:
            print(f"      * ç±»åˆ« {val}: {counts[val]} æ¡ ({percents[val]:.1f}%)")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºäºŒåˆ†ç±»
        n_unique = target_series.nunique()
        print(f"   - å”¯ä¸€å€¼æ•°é‡: {n_unique}")
        if n_unique == 2:
            print("   - æ•°æ®ç±»å‹: äºŒåˆ†ç±»é—®é¢˜")
        else:
            print(f"   - è­¦å‘Š: å‘ç°{n_unique}ä¸ªç±»åˆ«ï¼Œå¯èƒ½ä¸æ˜¯æ ‡å‡†äºŒåˆ†ç±»")
    
    def _feature_analysis(self):
        """åˆ†æç‰¹å¾å˜é‡"""
        print("\nã€3ã€‘ç‰¹å¾å˜é‡åˆ†æ")
        
        # åˆ†å‰²æ•°å€¼å‹å’Œç±»åˆ«å‹ç‰¹å¾
        self.numeric_cols = self.df.drop(columns=[self.target_col]).select_dtypes(include=[np.number]).columns.tolist()
        self.categorical_cols = [c for c in self.df.columns if c not in self.numeric_cols and c != self.target_col]
        
        print(f"   - æ•°å€¼å‹ç‰¹å¾: {len(self.numeric_cols)}ä¸ª")
        if len(self.numeric_cols) > 0:
            print(f"      å‰5ä¸ª: {self.numeric_cols[:5]}...")
        
        print(f"   - ç±»åˆ«å‹ç‰¹å¾: {len(self.categorical_cols)}ä¸ª")
        if len(self.categorical_cols) > 0:
            print(f"      å‰5ä¸ª: {self.categorical_cols[:5]}...")
        
        # æ•°å€¼å‹ç‰¹å¾ç»Ÿè®¡
        if len(self.numeric_cols) > 0:
            print("\n   - æ•°å€¼å‹ç‰¹å¾ç»Ÿè®¡æ‘˜è¦:")
            print(self.df[self.numeric_cols].describe().T[['min', 'mean', 'max']].head())
        
        # ç±»åˆ«å‹ç‰¹å¾ç»Ÿè®¡
        if len(self.categorical_cols) > 0:
            print("\n   - ç±»åˆ«å‹ç‰¹å¾å”¯ä¸€å€¼æ•°é‡:")
            for col in self.categorical_cols[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                n_unique = self.df[col].nunique()
                print(f"      * {col}: {n_unique}ä¸ªç±»åˆ«")
        
        # ä¿å­˜å®Œæ•´ç»Ÿè®¡æ‘˜è¦åˆ°CSV
        self._save_summary_csv()
    
    def _save_summary_csv(self):
        """ç”Ÿæˆå¹¶ä¿å­˜æ•°æ®æ‘˜è¦CSV"""
        summary = []
        for col in self.df.columns:
            summary.append({
                'column': col,
                'dtype': str(self.df[col].dtype),
                'n_unique': int(self.df[col].nunique(dropna=False)),
                'n_missing': int(self.df[col].isnull().sum()),
                'missing_rate': round(self.df[col].isnull().mean() * 100, 2)
            })
        
        summary_df = pd.DataFrame(summary)
        summary_path = os.path.join(self.output_dir, 'eda_summary.csv')
        summary_df.to_csv(summary_path, index=False)
        print(f"\n   - æ•°æ®æ‘˜è¦å·²ä¿å­˜: {summary_path}")
    
    def _generate_plots(self):
        """ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨"""
        print("\nã€4ã€‘ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
        
        # 1. ç›®æ ‡åˆ†å¸ƒæŸ±çŠ¶å›¾
        self._plot_target_distribution()
        
        # 2. æ•°å€¼å‹ç‰¹å¾ç›´æ–¹å›¾
        if len(self.numeric_cols) > 0:
            self._plot_histograms()
        
        # 3. ç›¸å…³æ€§çƒ­åŠ›å›¾
        if len(self.numeric_cols) >= 2:
            self._plot_correlation_heatmap()
        
        # 4. ç±»åˆ«å‹ç‰¹å¾åˆ†å¸ƒå›¾
        if len(self.categorical_cols) > 0:
            self._plot_categorical_counts()
    
    def _plot_target_distribution(self):
        """ç›®æ ‡å˜é‡åˆ†å¸ƒå›¾"""
        plt.figure(figsize=(8, 6))
        ax = sns.countplot(data=self.df, x=self.target_col)
        
        # æ·»åŠ ç™¾åˆ†æ¯”æ ‡æ³¨
        total = len(self.df)
        for p in ax.patches:
            height = p.get_height()
            ax.text(p.get_x() + p.get_width()/2., height + 5,
                    f'{height/total*100:.1f}%', ha="center")
        
        plt.title(f'Target Distribution: {self.target_col}', fontsize=14)
        plt.xlabel('Class')
        plt.ylabel('Count')
        plt.tight_layout()
        
        # ä¿å­˜
        save_path = os.path.join(self.plots_dir, 'target_distribution.png')
        plt.savefig(save_path, dpi=300)
        plt.close()
        print(f"   - ç›®æ ‡åˆ†å¸ƒå›¾: {save_path}")
    
    def _plot_histograms(self):
        """æ•°å€¼å‹ç‰¹å¾ç›´æ–¹å›¾ï¼ˆæœ€å¤š8ä¸ªï¼‰"""
        n_plots = min(8, len(self.numeric_cols))
        print(f"   - ç”Ÿæˆ{n_plots}ä¸ªç›´æ–¹å›¾...")
        
        for i, col in enumerate(self.numeric_cols[:n_plots]):
            plt.figure(figsize=(10, 4))
            
            # ç»˜åˆ¶ç›´æ–¹å›¾
            sns.histplot(self.df[col].dropna(), kde=True, bins=30)
            plt.title(f'Histogram: {col} (skew={self.df[col].skew():.2f})')
            plt.xlabel(col)
            plt.ylabel('Frequency')
            plt.tight_layout()
            
            # ä¿å­˜
            save_path = os.path.join(self.plots_dir, f'hist_{col}.png')
            plt.savefig(save_path, dpi=300)
            plt.close()
        
        print(f"      ä¿å­˜è‡³: {self.plots_dir}")
    
    def _plot_correlation_heatmap(self):
        """æ•°å€¼å‹ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾"""
        plt.figure(figsize=(12, 10))
        
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        corr = self.df[self.numeric_cols].corr()
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        mask = np.triu(np.ones_like(corr, dtype=bool))  # åªæ˜¾ç¤ºä¸‹ä¸‰è§’
        sns.heatmap(corr, mask=mask, cmap='coolwarm', center=0,
                    square=True, linewidths=.5, cbar_kws={"shrink": .8})
        
        plt.title('Numeric Features Correlation Matrix', fontsize=14)
        plt.tight_layout()
        
        # ä¿å­˜
        save_path = os.path.join(self.plots_dir, 'correlation_heatmap.png')
        plt.savefig(save_path, dpi=300)
        plt.close()
        print(f"   - ç›¸å…³æ€§çƒ­åŠ›å›¾: {save_path}")
    
    def _plot_categorical_counts(self):
        """ç±»åˆ«å‹ç‰¹å¾åˆ†å¸ƒå›¾ï¼ˆå‰3ä¸ªï¼‰"""
        print(f"   - ç”Ÿæˆç±»åˆ«å‹ç‰¹å¾åˆ†å¸ƒå›¾ï¼ˆå‰3ä¸ªï¼‰...")
        
        for col in self.categorical_cols[:3]:
            plt.figure(figsize=(10, 6))
            
            # ç»˜åˆ¶æ¡å½¢å›¾ï¼ˆæ˜¾ç¤ºå‰10ä¸ªæœ€å¸¸è§ç±»åˆ«ï¼‰
            data = self.df[col].value_counts().head(10)
            sns.barplot(x=data.values, y=data.index)
            
            plt.title(f'Top 10 Categories: {col}')
            plt.xlabel('Count')
            plt.tight_layout()
            
            # ä¿å­˜
            save_path = os.path.join(self.plots_dir, f'cat_{col}.png')
            plt.savefig(save_path, dpi=300)
            plt.close()
        
        print(f"      ä¿å­˜è‡³: {self.plots_dir}")


# ==================== æ¨¡å—è‡ªæµ‹ä»£ç  ====================
if __name__ == '__main__':
    print("="*60)
    print("EDAåˆ†ææ¨¡å—è‡ªæµ‹")
    print("="*60)
    
    # æ¨¡æ‹Ÿæ•°æ®
    import numpy as np
    
    # åˆ›å»ºç¤ºä¾‹DataFrame
    df_test = pd.DataFrame({
        'feature1': np.random.randn(100),
        'feature2': np.random.randint(0, 5, 100),
        'target': np.random.randint(1, 3, 100)
    })
    
    # æ‰§è¡Œåˆ†æ
    analyzer = EDAAnalyzer(df_test, output_dir="./test_outputs")
    analyzer.run_full_analysis()
    python
    print("\nâœ… è‡ªæµ‹å®Œæˆï¼è¯·æ£€æŸ¥ test_outputs æ–‡ä»¶å¤¹")